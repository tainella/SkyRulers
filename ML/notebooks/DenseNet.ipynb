{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f3ee6736",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import pint\n",
    "from pint import UnitRegistry\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "d92eb624",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_CI(df):\n",
    "    def celc(x):\n",
    "        ureg = UnitRegistry()\n",
    "        Q_ = ureg.Quantity\n",
    "        home = Q_(x, ureg.degC)\n",
    "        return home.to('degK')\n",
    "\n",
    "    def ream(x):\n",
    "        ureg = UnitRegistry()\n",
    "        Q_ = ureg.Quantity\n",
    "        home = Q_(x, ureg.degR)\n",
    "        return home.to('degK')\n",
    "    \n",
    "    celc_features = ['ZT1AB', 'ZTNAC', 'ZTOIL', 'ZT1A', 'GEGTMC', 'ZTNAC_D']\n",
    "    ream_features = ['ZTAMB']\n",
    "    \n",
    "    for cl in celc_features:\n",
    "        if cl in df.columns.to_list():\n",
    "            df[cl] = pd.Series(celc(df[cl].values))\n",
    "            \n",
    "    for cl in ream_features:\n",
    "        if cl in df.columns.to_list():\n",
    "            df[cl] = pd.Series(ream(df[cl].values))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def preprocess_file(df, corr_ther):\n",
    "    def delete_corr(df, ther):\n",
    "        was_corr = []\n",
    "        corr = df.corr()\n",
    "        for row in corr.iterrows():\n",
    "            for v_ind in range(len(row[1])):\n",
    "                if row[1][v_ind] > ther and row[1][v_ind] < 1: #ПЕРЕСЧИТАТЬ\n",
    "                    if (row[0] not in was_corr) and (row[1].index[v_ind] not in was_corr):\n",
    "                        print(row[0], row[1].index[v_ind], row[1][v_ind])\n",
    "                        was_corr.append(row[0])\n",
    "        print(len(was_corr))\n",
    "        return was_corr\n",
    "    #удалить лишние\n",
    "    df = df.drop(['flight_datetime', 'engine_id'], axis = 1)\n",
    "    \n",
    "    #виды фичей\n",
    "    to_categorical = ['number_blades', 'engine_position', 'engine_family', \n",
    "                  'manufacturer', 'aircraft_family', 'aircraft_type', 'aircraft_grp',\n",
    "                  'ac_manufacturer']\n",
    "    numerical = list(set(df.columns.to_list()) - set(to_categorical))\n",
    "    \n",
    "    #убрать те у которых больше 2/3 пропущены значения\n",
    "    for cl in numerical:\n",
    "        if (cl in df.columns.to_list()) and (len(df[cl]) * 2 / 3 < df[cl].isna().sum()):\n",
    "            df = df.drop([cl], axis = 1)\n",
    "    #обновить список числовых фияей\n",
    "    numerical = list(set(df.columns.to_list()) - set(to_categorical))\n",
    "    #заполнить оставшиеся пропуски нулями\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    #перевести в систему СИ\n",
    "    df = to_CI(df)\n",
    "\n",
    "    #убрать скоррелированные фичи\n",
    "    was_corr = delete_corr(df[numerical], corr_ther)\n",
    "    df.drop(was_corr, axis = 1)\n",
    "    #обновить список числовых фияей\n",
    "    numerical = list(set(df.columns.to_list()) - set(to_categorical))\n",
    "    \n",
    "    #скалировать данные\n",
    "    scaled_features = StandardScaler().fit_transform(df[numerical].values)\n",
    "    scaled_features_df = pd.DataFrame(scaled_features, index=df[numerical].index, columns=df[numerical].columns)\n",
    "    \n",
    "    scaled_features_df\n",
    "    #исправить типы данных категориальных фичей\n",
    "    for cl in to_categorical:\n",
    "        df[cl] = df[cl].astype(object)\n",
    "        #One Hot Encoding\n",
    "        one_hot = pd.get_dummies(df[cl])\n",
    "        scaled_features_df = scaled_features_df.join(one_hot)\n",
    "    \n",
    "    return scaled_features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a12e0160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCN12I ZPCN12 0.9970258301523474\n",
      "ZXM CAS 0.9735949806805446\n",
      "ZPCN12 PCN12 0.9961382830347263\n",
      "EGTHDM_D SLOATL_D 0.9998878735220914\n",
      "DELFN DELN1 0.9933118805746719\n",
      "PCN1AR PCN1BR 0.9992539707243598\n",
      "6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tainella/opt/anaconda3/lib/python3.9/site-packages/pandas/core/construction.py:616: UnitStrippedWarning: The unit of the quantity is stripped when downcasting to ndarray.\n",
      "  data = np.array(data, copy=copy)\n",
      "/var/folders/x4/7f4hrz657630_vzq5rhyrmbw0000gp/T/ipykernel_7508/2488415196.py:75: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  one_hot = pd.get_dummies(df[cl])\n",
      "/var/folders/x4/7f4hrz657630_vzq5rhyrmbw0000gp/T/ipykernel_7508/2488415196.py:75: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
      "  one_hot = pd.get_dummies(df[cl])\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/takeoff_CFM56-7B27-B1.csv\")       \n",
    "\n",
    "to_categorical = ['number_blades', 'engine_position', 'engine_family', \n",
    "                  'manufacturer', 'aircraft_family', 'aircraft_type', 'aircraft_grp',\n",
    "                  'ac_manufacturer', 'flight_datetime', 'engine_id']\n",
    "\n",
    "numerical = list(set(df.columns.to_list()) - set(to_categorical))\n",
    "\n",
    "df = preprocess_file(df, corr_ther = 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "d92114cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Целевые переменные\n",
    "\n",
    "y = pd.read_csv(\"../data/y.csv\")\n",
    "targets = y.columns.to_list()\n",
    "tr = [\"engine_id\", \"flight_datetime\", \"flight_phase\"]\n",
    "for t in tr:\n",
    "    targets.remove(t)\n",
    "\n",
    "tr = deepcopy(targets)\n",
    "for t in tr:\n",
    "    if t not in df.columns.to_list():\n",
    "        targets.remove(t)\n",
    "        \n",
    "features = list(set(df.columns.to_list()) - set(targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "2eda72f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BRAT',\n",
       " 'DELFN',\n",
       " 'DELN1',\n",
       " 'EGTHDM',\n",
       " 'EGTHDM_D',\n",
       " 'PCN12',\n",
       " 'PCN12I',\n",
       " 'PCN1AR',\n",
       " 'PCN1BR',\n",
       " 'PCN1K',\n",
       " 'SLOATL',\n",
       " 'SLOATL_D',\n",
       " 'ZPCN25_D',\n",
       " 'ZT49_D']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eab8a59",
   "metadata": {},
   "source": [
    "### Train test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "d776ce9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                  1,                   2,               'AGW',\n",
       "                   'ZVB1F',           'CFM56-7',              'B737',\n",
       "                      24.0,             'ZVB1R',       'n1_modifier',\n",
       "                    'ZT49',              'ZT1A',               'ZXM',\n",
       "                  'ZPCN12',               'IBP',             'ZVB2R',\n",
       "                'B737-800',          'B737-83N', 'CFM INTERNATIONAL',\n",
       "                   'IVS12',            'BOEING',               'IBE',\n",
       "                     'CAS',              'IAIE',            'ZPCN25',\n",
       "                   'ZVB2F',               'SAT',               'IAI',\n",
       "                    'ZALT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[features].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "5ff6071f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[features].values\n",
    "y = df['ZPCN25'].values.reshape(y.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "e36a87ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "0acd14a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset:\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = features\n",
    "        self.labels = targets\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        feat_ = torch.tensor(self.features[idx], dtype=torch.float)\n",
    "        label_ = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        \n",
    "        return feat_, label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "d1fc283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = MyDataset(X_train, y_train)\n",
    "training_loader = torch.utils.data.DataLoader(training_set, batch_size = 32)\n",
    "\n",
    "val_set = MyDataset(X_test, y_test)\n",
    "val_loader = torch.utils.data.DataLoader(val_set, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "3e4d935e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.0"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1] * 1.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07dbd39a",
   "metadata": {},
   "source": [
    "### Модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "9a7cd7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN,self).__init__()\n",
    "        self.layer1=nn.Linear(X_train.shape[1], X_train.shape[1] * 3)\n",
    "        self.layer2=nn.Linear(X_train.shape[1] * 3, X_train.shape[1] * 2)\n",
    "        self.layer3=nn.Linear(X_train.shape[1] * 2, X_train.shape[1] // 2)\n",
    "        self.layer4=nn.Linear(X_train.shape[1] // 2, y_train.shape[1])\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=F.relu(self.layer1(x))\n",
    "        x=F.relu(self.layer2(x))\n",
    "        x=F.relu(self.layer3(x))\n",
    "        x=self.layer4(x)\n",
    "        return x       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c4341691",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NN()\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=3e-2)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8262929e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs: 0......loss:0.17102083563804626\n",
      "epochs: 5......loss:0.08467797189950943\n"
     ]
    }
   ],
   "source": [
    "epochs=10\n",
    "for i in range(epochs):\n",
    "    for x_batch, y_batch in training_loader:\n",
    "        #initialize the model parameter\n",
    "        optimizer.zero_grad(set_to_none = True)\n",
    "        #calculate the loss\n",
    "        output = model.forward(x_batch)\n",
    "        loss = loss_fn(output, y_batch)\n",
    "        #backpropagation\n",
    "        loss.backward()\n",
    "        #update the parameters\n",
    "        optimizer.step()\n",
    "    if(i % 5 == 0):\n",
    "        print(f\"epochs: {i}......loss:{loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "f7db8358",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = model(torch.tensor(X_train,dtype=torch.float32,requires_grad=True))\n",
    "y_test_pred = model(torch.tensor(X_test,dtype=torch.float32))\n",
    "\n",
    "#convert to numpy array\n",
    "y_train_pred = y_train_pred.detach().numpy()\n",
    "y_test_pred = y_test_pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "ca27efbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train 0.163\n",
      "test 0.163\n"
     ]
    }
   ],
   "source": [
    "test_metric = sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "train_metric = sqrt(mean_squared_error(y_test, y_test_pred))\n",
    "print('train', round(train_metric, 3))\n",
    "print('test', round(test_metric, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd974b56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
